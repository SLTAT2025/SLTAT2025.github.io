# SLTAT 2025: Sessions Detail

9th Workshop on Sign Language Translation and Avatar Technologies.

List of accepted papers and sessions detail.

See the main SLTAT 2025 Home page <a href="https://sltat2025.github.io">https://sltat2025.github.io</a> for the overall program and other info.

Workshop day: 16 September 2025.

The workshop took place within the Intelligent Virtual Agents IVA2025 (<a href="https://iva.acm.org/2025/" target="_new">https://iva.acm.org/2025/</a>) conference at the HTW campus (directly at the river Spree) in Berlin, Germany.

Cite workshop as:

Nunnari, F., Luna-Jiménez, C., Wolfe, R., McDonald, J., Filhol, M., Efthimiou, E., Fotinea, E., Hanke, T. (2025) “9th International Workshop on Sign Language Translation and Avatar Technology (SLTAT 2025),” in Adjunct Proceedings of the 25th ACM International Conference on Intelligent Virtual Agents. IVA Adjunct ’25: ACM International Conference on Intelligent Virtual Agents, Berlin Germany: ACM, pp. 1–3. Available at: https://doi.org/10.1145/3742886.3759656.


## Session details

<table border=1 cellpadding=1 cellspacing=1>
 <tr>
  <td>Session</td>
  <td>ID</td>
  <td>Title (w/ link to ACM Digital Library)</td>
  <td>Authors</td>
  
 </tr>
 <tr>
  <td>Oral/Signed Presentations A (9:15-10:15)</td>
  <td>&nbsp;</td>
  <td>&nbsp;</td>
  <td>&nbsp;</td>
 </tr>
 <tr>
  <td></td>
  <td align=right>10</td>
  <td><a href="https://doi.org/10.1145/3742886.3756714" target="_new">Involvement
  of the Deaf Community in Large Scale Projects: Overview of SignON and EASIER
  Co-Creation Practices</a></td>
  <td>Lisa
  Bianca Lepp, Mirella De Sisto, Dimitar Shterionov</td>
 </tr>
 <tr>
  <td></td>
  <td align=right>30</td>
  <td><a href="https://doi.org/10.1145/3742886.3756738" target="_new">User
  Acceptance of Augmented Remote Sign Language Interpreting</a></td>
  <td>Zheng
  Dan Xia, Maartje de Meulder, Gomèr Otterspeer, Floris Roelofsen</td>
 </tr>
 <tr>
  <td></td>
  <td align=right>13</td>
  <td><a href="https://doi.org/10.1145/3742886.3756723" target="_new">Using
  Sign Language Production as Data Augmentation to enhance Sign Language
  Translation</a></td>
  <td>Harry
  Walsh, Maksym Ivashechkin, Richard Bowden</td>
 </tr>
 <tr>
  <td></td>
  <td>&nbsp;</td>
  <td>&nbsp;</td>
  <td>&nbsp;</td>
 </tr>
 <tr>
  <td>Posters A (11:00-12:30)</td>
  <td>&nbsp;</td>
  <td>&nbsp;</td>
  <td>&nbsp;</td>
 </tr>
 <tr>
  <td></td>
  <td align=right>1</td>
  <td><a href="https://doi.org/10.1145/3742886.3756718" target="_new">The
  Importance of Facial Features in Vision-based Sign Language Recognition:
  Eyes, Mouth or Full Face?</a></td>
  <td>Dinh
  Nam Pham, Eleftherios Avramidis</td>
 </tr>
 <tr>
  <td></td>
  <td align=right>2</td>
  <td><a href="https://doi.org/10.1145/3742886.3756736" target="_new">Designing
  a Marker Based Motion Capture Setup for Sign Language Research</a></td>
  <td>J.I.
  Andersen, Gomèr Otterspeer, Robert G. Belleman, Floris Roelofsen</td>
 </tr>
 <tr>
  <td></td>
  <td align=right>3</td>
  <td><a href="https://doi.org/10.1145/3742886.3756734" target="_new">Motion-Based
  Analysis of Personalization and Kinematic Features in Japanese Sign Language
  Video Data</a></td>
  <td>Zixuan
  Dai, Shinji Sako</td>
 </tr>
 <tr height=23 style='height:17.0pt'>
  <td height=23 style='height:17.0pt'></td>
  <td align=right>4</td>
  <td><a href="https://doi.org/10.1145/3742886.3756712" target="_new">Real-World
  Impacts of Sign Language Technologies</a></td>
  <td>Kevin
  Lee, Josephine Joo</td>
 </tr>
 <tr>
  <td></td>
  <td align=right>5</td>
  <td><a href="https://doi.org/10.1145/3742886.3756710" target="_new">MMS
  Player: an open source software for parametric data-driven animation of Sign
  Language avatars</a></td>
  <td>Fabrizio
  Nunnari, Shailesh Mishra, Patrick Gebhard</td>
 </tr>
 <tr>
  <td></td>
  <td align=right>7</td>
  <td><a href="https://doi.org/10.1145/3742886.3756711" target="_new">Enhancing
  Signing Avatar Torso Movement with Linguistic Features Using Interpretable
  Linear Models</a></td>
  <td>Shatabdi
  Choudhury</td>
 </tr>
 <tr>
  <td></td>
  <td align=right>8</td>
  <td><a href="https://doi.org/10.1145/3742886.3756729" target="_new">Sign
  Language Translation using Skip Connections and Selective Self-transfer
  Learning</a></td>
  <td>Takeshi
  Kajiyama, Tomoya Murakami, Taro Miyazaki, Hiroyuki Kaneko</td>
 </tr>
 <tr height=68 style='page-break-before:always;height:51.0pt'>
  <td></td>
  <td align=right>9</td>
  <td><a href="https://doi.org/10.1145/3742886.3756732" target="_new">Text-to-Sign
  Language Production via Intermediate Skeletal Representations using
  Transformers and Neural Rendering</a></td>
  <td>Chrysa
  Pratikaki, Stavroula - Evita Fotinea, Eleni Efthimiou, Panagiotis Filntisis,
  Anastasios Roussos, Petros Maragos</td>
 </tr>
 <tr>
  <td></td>
  <td align=right>11</td>
  <td><a href="https://doi.org/10.1145/3742886.3756717" target="_new">Modality
  Matters: Training and Tokenization Effects in Sign-to-Text Translation</a></td>
  <td>Gerard
  Sant, Amit Moryossef, Mathias Müller, Sarah Ebling</td>
 </tr>
 <tr>
  <td></td>
  <td align=right>14</td>
  <td><a href="https://doi.org/10.1145/3742886.3756704" target="_new">Placement
  Control Method for Sign Language Translation System</a></td>
  <td>Tsubasa
  Uchida, Kohei Hakozaki, Taro Miyazaki, Hiroyuki Kaneko</td>
 </tr>
 <tr>
  <td></td>
  <td align=right>15</td>
  <td><a href="https://doi.org/10.1145/3742886.3756722" target="_new">Towards
  Sign Language Motion Generation from Blurred Videos: System Development and
  Evaluation</a></td>
  <td>Tomoya
  Murakami, Kohei Hakozaki, Hiroyuki Kaneko</td>
 </tr>
 <tr>
  <td></td>
  <td align=right>18</td>
  <td><a href="https://doi.org/10.1145/3742886.3756724" target="_new">LLM-Driven
  Multimodal Video-Text Fusion for Isolated Sign Language Recognition</a></td>
  <td>Sergio
  Esteban-Romero, Cristina Luna-Jiménez, Manuel Gil-Martín, Fernando
  Fernández-Martínez, Elisabeth Andre</td>
 </tr>
 <tr>
  <td></td>
  <td align=right>G1</td>
  <td>Comparison of Deep Learning and Statistical Methods in Sign Language Recognition</td>
  <td>Caner Dogan</td>
 </tr>
 <tr>
  <td></td>
  <td>&nbsp;</td>
  <td>&nbsp;</td>
  <td>&nbsp;</td>
 </tr>
 <tr>
  <td>Posters B (14:00-15:30)</td>
  <td>&nbsp;</td>
  <td>&nbsp;</td>
  <td>&nbsp;</td>
 </tr>
 <tr>
  <td></td>
  <td align=right>20</td>
  <td><a href="https://doi.org/10.1145/3742886.3756725" target="_new">Translating
  Sentences from Written French into LSF Annotation</a></td>
  <td>Clément
  Reverdy, Sylvie Gibet, Pierre-François Marteau</td>
 </tr>
 <tr>
  <td></td>
  <td align=right>21</td>
  <td><a href="https://doi.org/10.1145/3742886.3756731" target="_new">Color
  histogram equalization and fine-tuning to improve expression recognition of
  (partially occluded) faces on sign language datasets</a></td>
  <td>Fabrizio
  Nunnari, Alakshendra Singh, Patrick Gebhard</td>
 </tr>
 <tr>
  <td></td>
  <td align=right>22</td>
  <td><a href="https://doi.org/10.1145/3742886.3756746" target="_new">Towards
  an AI-based Sign Language Video Editing Interface</a></td>
  <td>Hossein
  Ranjbar, Sarah Ebling, Alessia Battisti, Lisa Arter, Laura Setz</td>
 </tr>
 <tr>
  <td></td>
  <td align=right>23</td>
  <td><a href="https://doi.org/10.1145/3742886.3756720" target="_new">Sign
  Spotting Disambiguation using Large Language Models</a></td>
  <td>Low
  Jian He, Ozge Mercanoglu Sincan, Richard Bowden</td>
 </tr>
 <tr>
  <td height=91 style='height:68.0pt'></td>
  <td align=right>24</td>
  <td><a href="https://doi.org/10.1145/3742886.3756740" target="_new">Combining
  the user friendliness of SignWriting with the precision of linguistic
  parameters</a></td>
  <td>Antonio
  F. G. Sevilla, José María Lahoz-Bengoechea, Sandra Conde González, ALBERTO
  DIAZ, Pablo Folgueira Galán, Julia de la Calle Pérez</td>
 </tr>
 <tr>
  <td></td>
  <td align=right>25</td>
  <td><a href="https://doi.org/10.1145/3742886.3756733" target="_new">Exploring
  Sign-level Strategies to Enhance Automatic Translation of French Sign
  Language</a></td>
  <td>Diandra
  Fabre, Julie Lascar, Julie Halbout, Yanis Ouakrim, Annelies Braffort, Thomas
  Hueber, Michèle Gouiffès, Denis Beautemps</td>
 </tr>
 <tr>
  <td></td>
  <td align=right>26</td>
  <td><a href="https://doi.org/10.1145/3742886.3756707" target="_new">Hierarchical
  Feature Alignment for Gloss-Free Sign Language Translation</a></td>
  <td>Sobhan
  Asasi, Mohamed Ilyes Lakhal, Richard Bowden</td>
 </tr>
 <tr>
  <td></td>
  <td align=right>28</td>
  <td><a href="https://doi.org/10.1145/3742886.3756716" target="_new">Preprocessing
  MediaPipe Joint Annotation for Sign Language Similarity Analysis</a></td>
  <td>Kehina
  Manseri, Sam Bigeard, Slim Ouni</td>
 </tr>
 <tr>
  <td></td>
  <td align=right>31</td>
  <td><a href="https://doi.org/10.1145/3742886.3756703" target="_new">Contrastive
  Pretraining with Dual Visual Encoders for Gloss-Free Sign Language
  Translation</a></td>
  <td>Ozge
  Mercanoglu Sincan, Richard Bowden</td>
 </tr>
 <tr>
  <td></td>
  <td align=right>32</td>
  <td><a href="https://doi.org/10.1145/3742886.3756706" target="_new">Challenges
  and opportunities in portraying emotion in generated sign language</a></td>
  <td>John
  C. McDonald, Rosalee Wolfe, Fabrizio Nunnari</td>
 </tr>
 <tr>
  <td></td>
  <td align=right>35</td>
  <td><a href="https://doi.org/10.1145/3742886.3756719" target="_new">Evaluation
  of a Sign Language Avatar on Comprehensibility, User Experience &amp;
  Acceptability</a></td>
  <td>Fenya
  Wasseroth, Eleftherios Avramidis, Vera Czehmann, Tanja Kojic, Fabrizio
  Nunnari, Sebastian Möller</td>
 </tr>
 <tr height=113 style='height:85.0pt'>
  <td height=113 style='height:85.0pt'></td>
  <td align=right>37</td>
  <td><a href="https://doi.org/10.1145/3742886.3756709" target="_new">The TUB Sign Language Corpus Collection</a></td>
  <td>Eleftherios
  Avramidis, Vera Czehmann, Fabian Decker, Lorenz Hufe, Aljoscha Lipski, Yuni
  Amaloa Quintero Villalobos,
  Mengqian Shi, Tae Kwon Rhee, Lennart Stölting, Fabrizio Nunnari, Sebastian
  Möller</td>
 </tr>
 <tr>
  <td></td>
  <td>&nbsp;</td>
  <td>&nbsp;</td>
  <td>&nbsp;</td>
 </tr>
 <tr>
  <td>Oral/Signed Presentations B (16:00-17:00)</td>
  <td>&nbsp;</td>
  <td>&nbsp;</td>
  <td>&nbsp;</td>
 </tr>
 <tr>
  <td></td>
  <td align=right>34</td>
  <td><a href="https://doi.org/10.1145/3742886.3756708" target="_new">Spotter+GPT:
  Turning Sign Spottings into Sentences with LLMs</a></td>
  <td>Ozge
  Mercanoglu Sincan, Richard Bowden</td>
 </tr>
 <tr>
  <td></td>
  <td align=right>17</td>
  <td><a href="https://doi.org/10.1145/3742886.3756728" target="_new">Towards
  Skeletal and Signer Noise Reduction in Sign Language Production via
  Quaternion-Based Pose Encoding and Contrastive Learning</a></td>
  <td>Guilhem
  Fauré, Mostafa SADEGHI, Sam Bigeard, Slim Ouni</td>
 </tr>
 <tr>
  <td></td>
  <td align=right>36</td>
  <td><a href="https://doi.org/10.1145/3742886.3756726" target="_new">Motion
  Capture Driven Avatars for Swedish Sign Language</a></td>
  <td>Anna
  Klezovich, Johanna Mesch, Jonas Beskow</td>
 </tr>
</table>
