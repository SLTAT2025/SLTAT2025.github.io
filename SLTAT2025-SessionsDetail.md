# SLTAT 2025: Sessions Detail

9th Workshop on Sign Language Translation and Avatar Technologies.

List of accepted papers and sessions detail.

See the main SLTAT 2025 Home page <a href="https://sltat2025.github.io">https://sltat2025.github.io</a> for the overall program and other info.

Workshop day: 16 September 2025.

The workshop will take place within the Intelligent Virtual Agents IVA2025 (<a href="https://iva.acm.org/2025/" target="_new">https://iva.acm.org/2025/</a>) conference at the HTW campus (directly at the river Spree) in Berlin, Germany.


## Session details

<table border=1 cellpadding=1 cellspacing=1>
 <tr>
  <td>Session</td>
  <td>ID</td>
  <td>Title</td>
  <td>Authors</td>
 </tr>
 <tr>
  <td>Oral/Signed Presentations A</td>
  <td>&nbsp;</td>
  <td>&nbsp;</td>
  <td>&nbsp;</td>
 </tr>
 <tr>
  <td></td>
  <td align=right>10</td>
  <td>Involvement
  of the Deaf Community in Large Scale Projects: Overview of SignON and EASIER
  Co-Creation Practices</td>
  <td>Lisa
  Bianca Lepp, Mirella De Sisto, Dimitar Shterionov</td>
 </tr>
 <tr>
  <td></td>
  <td align=right>30</td>
  <td>User
  Acceptance of Augmented Remote Sign Language Interpreting</td>
  <td>Zheng
  Dan Xia, Maartje de Meulder, Gomèr Otterspeer, Floris Roelofsen</td>
 </tr>
 <tr>
  <td></td>
  <td align=right>13</td>
  <td>Using
  Sign Language Production as Data Augmentation to enhance Sign Language
  Translation</td>
  <td>Harry
  Walsh, Maksym Ivashechkin, Richard Bowden</td>
 </tr>
 <tr>
  <td></td>
  <td>&nbsp;</td>
  <td>&nbsp;</td>
  <td>&nbsp;</td>
 </tr>
 <tr>
  <td>Posters A</td>
  <td>&nbsp;</td>
  <td>&nbsp;</td>
  <td>&nbsp;</td>
 </tr>
 <tr>
  <td></td>
  <td align=right>1</td>
  <td>The
  Importance of Facial Features in Vision-based Sign Language Recognition:
  Eyes, Mouth or Full Face?</td>
  <td>Dinh
  Nam Pham, Eleftherios Avramidis</td>
 </tr>
 <tr>
  <td></td>
  <td align=right>2</td>
  <td>Designing
  a Marker Based Motion Capture Setup for Sign Language Research</td>
  <td>J.I.
  Andersen, Gomèr Otterspeer, Robert G. Belleman, Floris Roelofsen</td>
 </tr>
 <tr>
  <td></td>
  <td align=right>3</td>
  <td>Motion-Based
  Analysis of Personalization and Kinematic Features in Japanese Sign Language
  Video Data</td>
  <td>Zixuan
  Dai, Shinji Sako</td>
 </tr>
 <tr height=23 style='height:17.0pt'>
  <td height=23 style='height:17.0pt'></td>
  <td align=right>4</td>
  <td>Real-World
  Impacts of Sign Language Technologies</td>
  <td>Kevin
  Lee, Josephine Joo</td>
 </tr>
 <tr>
  <td></td>
  <td align=right>5</td>
  <td>MMS
  Player: an open source software for parametric data-driven animation of Sign
  Language avatars</td>
  <td>Fabrizio
  Nunnari, Shailesh Mishra, Patrick Gebhard</td>
 </tr>
 <tr>
  <td></td>
  <td align=right>7</td>
  <td>Enhancing
  Signing Avatar Torso Movement with Linguistic Features Using Interpretable
  Linear Models</td>
  <td>Shatabdi
  Choudhury</td>
 </tr>
 <tr>
  <td></td>
  <td align=right>8</td>
  <td>Sign
  Language Translation using Skip Connections and Selective Self-transfer
  Learning</td>
  <td>Takeshi
  Kajiyama, Tomoya Murakami, Taro Miyazaki, Hiroyuki Kaneko</td>
 </tr>
 <tr height=68 style='page-break-before:always;height:51.0pt'>
  <td></td>
  <td align=right>9</td>
  <td>Text-to-Sign
  Language Production via Intermediate Skeletal Representations using
  Transformers and Neural Rendering</td>
  <td>Chrysa
  Pratikaki, Stavroula - Evita Fotinea, Eleni Efthimiou, Panagiotis Filntisis,
  Anastasios Roussos, Petros Maragos</td>
 </tr>
 <tr>
  <td></td>
  <td align=right>11</td>
  <td>Modality
  Matters: Training and Tokenization Effects in Sign-to-Text Translation</td>
  <td>Gerard
  Sant, Amit Moryossef, Mathias Müller, Sarah Ebling</td>
 </tr>
 <tr>
  <td></td>
  <td align=right>14</td>
  <td>Placement
  Control Method for Sign Language Translation System</td>
  <td>Tsubasa
  Uchida, Kohei Hakozaki, Taro Miyazaki, Hiroyuki Kaneko</td>
 </tr>
 <tr>
  <td></td>
  <td align=right>15</td>
  <td>Towards
  Sign Language Motion Generation from Blurred Videos: System Development and
  Evaluation</td>
  <td>Tomoya
  Murakami, Kohei Hakozaki, Hiroyuki Kaneko</td>
 </tr>
 <tr>
  <td></td>
  <td align=right>18</td>
  <td>LLM-Driven
  Multimodal Video-Text Fusion for Isolated Sign Language Recognition</td>
  <td>Sergio
  Esteban-Romero, Cristina Luna-Jiménez, Manuel Gil-Martín, Fernando
  Fernández-Martínez, Elisabeth Andre</td>
 </tr>
 <tr>
  <td></td>
  <td>&nbsp;</td>
  <td>&nbsp;</td>
  <td>&nbsp;</td>
 </tr>
 <tr>
  <td>Posters B</td>
  <td>&nbsp;</td>
  <td>&nbsp;</td>
  <td>&nbsp;</td>
 </tr>
 <tr>
  <td></td>
  <td align=right>20</td>
  <td>Translating
  Sentences from Written French into LSF Annotation</td>
  <td>Clément
  Reverdy, Sylvie Gibet, Pierre-François Marteau</td>
 </tr>
 <tr>
  <td></td>
  <td align=right>21</td>
  <td>Color
  histogram equalization and fine-tuning to improve expression recognition of
  (partially occluded) faces on sign language datasets</td>
  <td>Fabrizio
  Nunnari, Alakshendra Singh, Patrick Gebhard</td>
 </tr>
 <tr>
  <td></td>
  <td align=right>22</td>
  <td>Towards
  an AI-based Sign Language Video Editing Interface</td>
  <td>Hossein
  Ranjbar, Sarah Ebling, Alessia Battisti, Lisa Arter, Laura Setz</td>
 </tr>
 <tr>
  <td></td>
  <td align=right>23</td>
  <td>Sign
  Spotting Disambiguation using Large Language Models</td>
  <td>Low
  Jian He, Ozge Mercanoglu Sincan, Richard Bowden</td>
 </tr>
 <tr height=91 style='height:68.0pt'>
  <td height=91 style='height:68.0pt'></td>
  <td align=right>24</td>
  <td>Combining
  the user friendliness of SignWriting with the precision of linguistic
  parameters</td>
  <td>Antonio
  F. G. Sevilla, José María Lahoz-Bengoechea, Sandra Conde González, ALBERTO
  DIAZ, Pablo Folgueira Galán, Julia de la Calle Pérez</td>
 </tr>
 <tr height=68 style='page-break-before:always;height:51.0pt'>
  <td></td>
  <td align=right>25</td>
  <td>Exploring
  Sign-level Strategies to Enhance Automatic Translation of French Sign
  Language</td>
  <td>Diandra
  Fabre, Julie Lascar, Julie Halbout, Yanis Ouakrim, Annelies Braffort, Thomas
  Hueber, Michèle Gouiffès, Denis Beautemps</td>
 </tr>
 <tr>
  <td></td>
  <td align=right>26</td>
  <td>Hierarchical
  Feature Alignment for Gloss-Free Sign Language Translation</td>
  <td>Sobhan
  Asasi, Mohamed Ilyes Lakhal, Richard Bowden</td>
 </tr>
 <tr>
  <td></td>
  <td align=right>28</td>
  <td>Preprocessing
  MediaPipe Joint Annotation for Sign Language Similarity Analysis</td>
  <td>Kehina
  Manseri, Sam Bigeard, Slim Ouni</td>
 </tr>
 <tr>
  <td></td>
  <td align=right>31</td>
  <td>Contrastive
  Pretraining with Dual Visual Encoders for Gloss-Free Sign Language
  Translation</td>
  <td>Ozge
  Mercanoglu Sincan, Richard Bowden</td>
 </tr>
 <tr>
  <td></td>
  <td align=right>32</td>
  <td>Challenges
  and opportunities in portraying emotion in generated sign language</td>
  <td>John
  C. McDonald, Rosalee Wolfe, Fabrizio Nunnari</td>
 </tr>
 <tr>
  <td></td>
  <td align=right>35</td>
  <td>Evaluation
  of a Sign Language Avatar on Comprehensibility, User Experience &amp;
  Acceptability</td>
  <td>Fenya
  Wasseroth, Eleftherios Avramidis, Vera Czehmann, Tanja Kojic, Fabrizio
  Nunnari, Sebastian Möller</td>
 </tr>
 <tr height=113 style='height:85.0pt'>
  <td height=113 style='height:85.0pt'></td>
  <td align=right>37</td>
  <td>The
  SiLCC Sign Language Corpus Collection</td>
  <td>Eleftherios
  Avramidis, Vera Czehmann, Fabian Decker, Lorenz Jufe, Aljoscha Lipski, Yuni
  Amaloa Quintero Villalobos,
  Mengqian Shi, Tae Kwon Rhee, Lennart Stölting, Fabrizio Nunnari, Sebastian
  Möller</td>
 </tr>
 <tr>
  <td></td>
  <td>&nbsp;</td>
  <td>&nbsp;</td>
  <td>&nbsp;</td>
 </tr>
 <tr>
  <td>Oral/Signed Presentations B</td>
  <td>&nbsp;</td>
  <td>&nbsp;</td>
  <td>&nbsp;</td>
 </tr>
 <tr>
  <td></td>
  <td align=right>34</td>
  <td>Spotter+GPT:
  Turning Sign Spottings into Sentences with LLMs</td>
  <td>Ozge
  Mercanoglu Sincan, Richard Bowden</td>
 </tr>
 <tr>
  <td></td>
  <td align=right>17</td>
  <td>Towards
  Skeletal and Signer Noise Reduction in Sign Language Production via
  Quaternion-Based Pose Encoding and Contrastive Learning</td>
  <td>Guilhem
  Fauré, Mostafa SADEGHI, Sam Bigeard, Slim Ouni</td>
 </tr>
 <tr>
  <td></td>
  <td align=right>36</td>
  <td>Motion
  Capture Driven Avatars for Swedish Sign Language</td>
  <td>Anna
  Klezovich, Johanna Mesch, Jonas Beskow</td>
 </tr>
</table>

